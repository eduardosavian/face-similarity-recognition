{"cells":[{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"P6HQZsrvF5W9"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"m5EZG6UZF_xM"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"47aGH0tqWZ4i","executionInfo":{"status":"ok","timestamp":1701897924610,"user_tz":180,"elapsed":5520,"user":{"displayName":"P Marques","userId":"11489392348756606379"}}},"outputs":[],"source":["from zipfile import ZipFile\n","import numpy as np\n","import cv2\n","import warnings\n","import pandas as pd\n","from io import BytesIO\n","# caso for usar o Google Colab com a OpenCV, usar a lib abaixo\n","from google.colab.patches import cv2_imshow\n","import sqlite3 as sql\n","from os.path import join\n","\n","from keras.applications.vgg16 import VGG16\n","from keras.models import Model\n","from keras.layers import Flatten\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Input\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import GlobalMaxPooling2D\n","from keras.layers import GlobalAveragePooling2D\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import get_file\n","from keras import backend as K\n","from keras.applications.imagenet_utils import decode_predictions\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras.utils import get_source_inputs\n","from keras.callbacks import ModelCheckpoint\n","#from keras.layers.merge import concatenate\n","from __future__ import print_function\n","from tensorflow.python.keras.utils import layer_utils\n","from tensorflow.python.keras.utils.layer_utils import get_source_inputs\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from keras.layers import Dropout\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_midVO_CII28","executionInfo":{"status":"ok","timestamp":1701876853441,"user_tz":180,"elapsed":23804,"user":{"displayName":"Eduardo","userId":"03106774322600334169"}},"outputId":"34ffab1d-141e-4a97-80a6-c48228645619"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Loading files"],"metadata":{"id":"l9RJgkiMGWlM"}},{"cell_type":"code","source":["base_path = '/content/drive/MyDrive/PDI_EduardoSavian_PabloMarques_VitorCoelho_YuriRodrigues/Colab Notebooks/'"],"metadata":{"id":"iw5WFcbmGU9G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dt_path = join(base_path, 'data')\n","db_path = join(dt_path, 'dataset.db')\n","ds_o_path = join(dt_path, 'data.zip')\n","ds_t_path = join(dt_path, 'data_test.zip')"],"metadata":{"id":"OSvFlZmzFTaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"flCxwQoWG6lG"},"outputs":[],"source":["# Conectando no banco de dados\n","with sql.connect(db_path) as connection:\n","  cursor = connection.cursor()\n","\n","  # Executar a consulta SQL\n","  cursor.execute(\"DROP TABLE IF EXISTS dt_Pessoas\")\n","\n","  # Commit para aplicar as alterações ao banco de dados\n","  connection.commit()\n","  consulta_sql = '''\n","        CREATE TABLE IF NOT EXISTS dt_Pessoas(\n","            id INTEGER PRIMARY KEY,\n","            nome_pessoa TEXT,\n","            NomeImagem TEXT,\n","            imagem BLOB\n","        )\n","  '''\n","\n","  cursor.execute(consulta_sql)\n","\n","  connection.commit()\n","\n","  # images.to_sql('Pessoas',connection,index=True,if_exists='replace')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tj9TeyyLtPx8"},"outputs":[],"source":["def read_image_from_zip_insert_sql(zip_path,img_size,img_limit,connection):\n","  cursor = connection.cursor()\n","\n","  with ZipFile(zip_path, 'r') as zip_file:\n","    for item in zip_file.infolist():\n","            # Verifica se o item é um diretório (pasta)\n","            if item.is_dir():\n","                # Obtém o nome do diretório\n","                folder_name = item.filename\n","\n","                listOfItens = zip_file.infolist()[:img_limit] if img_limit > 0 else zip_file.infolist()\n","\n","                # Itera sobre todos os itens dentro do diretório\n","                for sub_item in listOfItens:\n","                    # Verifica se o item pertence ao diretório atual\n","                    if sub_item.filename.startswith(folder_name) and not sub_item.is_dir():\n","                      # Lê o conteúdo do arquivo zip\n","                      image_data = zip_file.read(sub_item.filename)\n","\n","                      nparr = np.frombuffer(image_data, np.uint8)\n","\n","                      # Lê a imagem usando o OpenCV\n","                      '''img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n","                      img = cv2.resize(img, (img_size, img_size))'''\n","                      if folder_name.split('/')[1] != '':\n","                        nome_pessoa = folder_name.split('/')[1]\n","                        consultaSQL=f\"\"\"INSERT INTO dt_Pessoas(nome_pessoa,imagem) VALUES ('{nome_pessoa}',?)\"\"\"\n","                        cursor.execute(consultaSQL,(sql.Binary(image_data),))\n","\n","  connection.commit()"]},{"cell_type":"code","source":["with sql.connect(db_path) as connection:\n","  read_image_from_zip_insert_sql(ds_o_path,224,3000,connection)"],"metadata":{"id":"H-9-4xK1G142"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6j9bkFSxqiDi","outputId":"11f47697-c6d0-4c3f-b72c-4772c8709f0b","executionInfo":{"status":"ok","timestamp":1701865987117,"user_tz":180,"elapsed":13,"user":{"displayName":"Eduardo","userId":"03106774322600334169"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["567\n"]}],"source":["num_pessoas = 0\n","\n","with sql.connect(db_path) as connection:\n","  cursor = connection.cursor()\n","  cursor.execute('SELECT COUNT(DISTINCT nome_pessoa) FROM dt_Pessoas')\n","  connection.commit()\n","\n","  num_pessoas = cursor.fetchone()[0]\n","print(num_pessoas)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ceFxjSbOMU3t"},"outputs":[],"source":["#Vitor\n","def read_image_from_zip_return_df(zip_path,img_size,img_limit):\n","  images = []\n","  with ZipFile(zip_path, 'r') as zip_file:\n","    for item in zip_file.infolist():\n","            # Verifica se o item é um diretório (pasta)\n","            if item.is_dir():\n","                # Obtém o nome do diretório\n","                folder_name = item.filename\n","\n","                listOfItens = zip_file.infolist()[:img_limit] if img_limit > 0 else zip_file.infolist()\n","\n","                # Itera sobre todos os itens dentro do diretório\n","                for sub_item in listOfItens:\n","                    # Verifica se o item pertence ao diretório atual\n","                    if sub_item.filename.startswith(folder_name) and not sub_item.is_dir():\n","                      # Lê o conteúdo do arquivo zip\n","                      image_data = zip_file.read(sub_item.filename)\n","\n","                      nparr = np.frombuffer(image_data, np.uint8)\n","\n","                      # Lê a imagem usando o OpenCV\n","                      img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n","                      img = cv2.resize(img, (img_size, img_size))\n","                      if folder_name.split('/')[1] != '':\n","                        images.append((folder_name,folder_name.split('/')[1], sub_item.filename, img))\n","    pd_images = pd.DataFrame(data=images,columns=['dir','Pessoa','NomeImagem','Imagem'])\n","\n","    return pd_images\n","\n","# images = read_image_from_zip_return_df(ds_o_path,224,0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfkjmPG2tO7H"},"outputs":[],"source":["# del images"]},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"kcrqjYwpGcTl"}},{"cell_type":"markdown","source":["### Creating"],"metadata":{"id":"yu9nJDnuGyIJ"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGfd5HmErKqR","outputId":"ded4fa00-b5bf-45b8-ee73-1689848f1f4b","executionInfo":{"status":"ok","timestamp":1701897952819,"user_tz":180,"elapsed":8879,"user":{"displayName":"P Marques","userId":"11489392348756606379"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467096/553467096 [==============================] - 4s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fc1 (Dense)                 (None, 4096)              102764544 \n","                                                                 \n"," fc2 (Dense)                 (None, 4096)              16781312  \n","                                                                 \n"," predictions (Dense)         (None, 1000)              4097000   \n","                                                                 \n","=================================================================\n","Total params: 138357544 (527.79 MB)\n","Trainable params: 138357544 (527.79 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model = VGG16()\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"eTkSTXuCnM5s","outputId":"b0679575-000c-4dfc-aaac-35a31c151240","executionInfo":{"status":"ok","timestamp":1701865990789,"user_tz":180,"elapsed":16,"user":{"displayName":"Eduardo","userId":"03106774322600334169"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.10,preprocessing_function = preprocess_input)\\ndir_data='/content/drive/MyDrive/ML repository/Image Classification/Colab Notebooks/data'\\ntrain_generator = train_datagen.flow_from_directory(\\n    dir_data,\\n    target_size=(224, 224),\\n    batch_size=32,\\n    class_mode='categorical',\\n    #shuffle=True,\\n    subset='training')\\n\\n\\nvalidation_generator = train_datagen.flow_from_directory(\\n    dir_data,\\n    target_size=(224, 224),\\n    batch_size=32,\\n    class_mode='categorical',\\n    #shuffle=True,\\n    subset='validation')\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":50}],"source":["# Configuração dos geradores de dados\n","# Vitor\n","'''\n","train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.10,preprocessing_function = preprocess_input)\n","dir_data='/content/drive/MyDrive/ML repository/Image Classification/Colab Notebooks/data'\n","train_generator = train_datagen.flow_from_directory(\n","    dir_data,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    #shuffle=True,\n","    subset='training')\n","\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    dir_data,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    #shuffle=True,\n","    subset='validation')\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2TjKzgRc9Rd","outputId":"de987f6a-7b11-4a77-cbbf-41dd25b61103","executionInfo":{"status":"ok","timestamp":1701865991646,"user_tz":180,"elapsed":871,"user":{"displayName":"Eduardo","userId":"03106774322600334169"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"FaceRecognition\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," bloco1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," bloco1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," bloco1_pool1 (MaxPooling2D  (None, 112, 112, 64)      0         \n"," )                                                               \n","                                                                 \n"," bloco2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," bloco2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," bloco2_pool1 (MaxPooling2D  (None, 56, 56, 128)       0         \n"," )                                                               \n","                                                                 \n"," bloco3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," bloco3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," bloco3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," bloco3_pool1 (MaxPooling2D  (None, 28, 28, 256)       0         \n"," )                                                               \n","                                                                 \n"," bloco4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," bloco4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," bloco4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," bloco4_pool1 (MaxPooling2D  (None, 14, 14, 512)       0         \n"," )                                                               \n","                                                                 \n"," bloco5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," bloco5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," bloco5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," bloco5_pool1 (MaxPooling2D  (None, 7, 7, 512)         0         \n"," )                                                               \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fc1 (Dense)                 (None, 4096)              102764544 \n","                                                                 \n"," fc2 (Dense)                 (None, 4096)              16781312  \n","                                                                 \n"," predictions (Dense)         (None, 567)               2322999   \n","                                                                 \n","=================================================================\n","Total params: 136583543 (521.02 MB)\n","Trainable params: 2322999 (8.86 MB)\n","Non-trainable params: 134260544 (512.16 MB)\n","_________________________________________________________________\n"]}],"source":["# def VGGUpdate(classes,input_tensor=None):\n","# Pablo\n","img_rows,img_cols = 224,224\n","img_channels = 3\n","\n","img_dim = (img_rows, img_cols, img_channels)\n","\n","img_input = Input(img_dim,sparse=False)\n","\n","# Bloco 1\n","x = Conv2D(64,(3,3),activation='relu',padding='same',name='bloco1_conv1',trainable=False)(img_input)\n","x = Conv2D(64,(3,3),activation='relu',padding='same',name='bloco1_conv2',trainable=False)(x)\n","x = MaxPooling2D((2,2),strides=(2, 2),name='bloco1_pool1',trainable=False)(x)\n","# Bloco 2\n","x = Conv2D(128,(3,3),activation='relu',padding='same',name='bloco2_conv1',trainable=False)(x)\n","x = Conv2D(128,(3,3),activation='relu',padding='same',name='bloco2_conv2',trainable=False)(x)\n","x = MaxPooling2D((2,2),strides=(2,2),name='bloco2_pool1',trainable=False)(x)\n","# Bloco 3\n","x = Conv2D(256,(3,3),activation='relu',padding='same',name='bloco3_conv1',trainable=False)(x)\n","x = Conv2D(256,(3,3),activation='relu',padding='same',name='bloco3_conv2',trainable=False)(x)\n","x = Conv2D(256,(3,3),activation='relu',padding='same',name='bloco3_conv3',trainable=False)(x)\n","x = MaxPooling2D((2,2),strides=(2,2),name='bloco3_pool1',trainable=False)(x)\n","# Bloco 4\n","x = Conv2D(512,(3,3),activation='relu',padding='same',name='bloco4_conv1',trainable=False)(x)\n","x = Conv2D(512,(3,3),activation='relu',padding='same',name='bloco4_conv2',trainable=False)(x)\n","x = Conv2D(512,(3,3),activation='relu',padding='same',name='bloco4_conv3',trainable=False)(x)\n","x = MaxPooling2D((2,2),strides=(2,2),name='bloco4_pool1',trainable=False)(x)\n","# Bloco 5\n","x = Conv2D(512,(3,3),activation='relu',padding='same',name='bloco5_conv1',trainable=False)(x)\n","x = Conv2D(512,(3,3),activation='relu',padding='same',name='bloco5_conv2',trainable=False)(x)\n","x = Conv2D(512,(3,3),activation='relu',padding='same',name='bloco5_conv3',trainable=False)(x)\n","x = MaxPooling2D((2,2),strides=(2,2),name='bloco5_pool1',trainable=False)(x)\n","\n","# x = model.output\n","# Classificação\n","x =  Flatten(name='flatten',trainable=False)(x)\n","x =  Dense(4096,activation='relu',name='fc1', trainable=False)(x)\n","x =  Dense(4096,activation='relu',name='fc2', trainable=False)(x)\n","\n","# DESCOMENTAR ESSE QUANDO FOR USAR IMAGENS DO IMAGEDATAGENERATOR\n","# x =  Dense(validation_generator.num_classes,activation='softmax',name='predictions')(x)\n","\n","# DESCOMENTAR ESSE QUANDO FOR USAR IMAGENS DO ZIP\n","# x =  Dense(len(images[\"Pessoa\"].unique()),activation='softmax',name='predictions', trainable=True)(x)\n","\n","# DESCOMENTAR ESSE QUANDO FOR USAR IMAGENS DO SQL\n","x =  Dense(num_pessoas,activation='softmax',name='predictions', trainable=True)(x)\n","\n","# model = Model(inputs=model.input, outputs=x, name='FaceRecognition')\n","\n","model = Model(inputs=img_input, outputs=x, name='FaceRecognition')\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model.summary()\n","\n","# return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Td73MoNzrEHL"},"outputs":[],"source":["# model = VGGUpdate(classes=len(images['Pessoa'].unique()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5d6zswkstyLT"},"outputs":[],"source":["#Vitor\n","arr_img = []\n","arr_pessoas = []\n","img_size = 224\n","with sql.connect(db_path) as connection:\n","    connection.row_factory = sql.Row\n","    cursor = connection.cursor()\n","\n","    cursor.execute(\"SELECT nome_pessoa, imagem FROM dt_Pessoas\")\n","\n","\n","    connection.commit()\n","\n","    response = cursor.fetchall()\n","\n","    for dados_imagem in response:\n","      imagem_array = np.frombuffer(dados_imagem['imagem'], dtype=np.uint8)\n","      imagemLinha = cv2.imdecode(imagem_array, cv2.IMREAD_COLOR)\n","      imagemLinha = cv2.resize(imagemLinha, (img_size,img_size))\n","      arr_img.append(imagemLinha)\n","      arr_pessoas.append(dados_imagem['nome_pessoa'])\n","\n","arr_imgNP = np.array(arr_img)\n","arr_pessoasNP = np.array(arr_pessoas)\n","\n","arr_images255 = arr_imgNP.astype('float32')# / 255.0\n","#cv2_imshow(arr_images255[10])\n","#print(arr_pessoasNP[10])\n","\n","Pessoas_Nome = arr_pessoasNP\n","Pessoas_Nome_Unique = np.unique(arr_pessoasNP)\n","#print(arr_pessoasNP)\n","\n","#LabelEncoder\n","y_encoder = LabelEncoder()\n","Pessoas = y_encoder.fit_transform(Pessoas_Nome)\n","#print(Pessoas)\n","\n","#ColumnTransformer\n","Pessoas = Pessoas.reshape(-1,1)\n","Y = ColumnTransformer([('Pessoa',OneHotEncoder(),[0])], remainder = 'passthrough').fit_transform(Pessoas)\n","\n","\n","#Split\n","arr_images255, Y = shuffle(arr_images255, Y, random_state=1)\n","\n","train_x, test_x, train_y, test_y = train_test_split(arr_images255, Y, test_size=0.2, random_state=415)\n","train_y = train_y.toarray()\n","test_y = test_y.toarray()\n","# print(train_y[0])\n","# print(Pessoas_Nome_Unique[np.argmax(train_y[0])])\n","# cv2_imshow(train_x[0])\n","# print(arr_pessoasNP[np.argmax(train_y[3])])"]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"6WH5rya2Gvgu"}},{"cell_type":"code","source":["models_path = join(base_path, 'models')\n","model_path = join(models_path, 'model.h5')\n","cmodel_path= join(models_path, 'cmodel.h5')"],"metadata":{"id":"qb2b8ClOFl1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4GxCy-LzM8ta"},"outputs":[],"source":["#Yuri\n","checkpoint_filepath=cmodel_path\n","load_filepath=model_path\n","Checkpoint = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_best_only=True,\n","    monitor='val_accuracy',\n","    mode='max',\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dt-E5pMYPADR","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1701865998930,"user_tz":180,"elapsed":3443,"user":{"displayName":"Eduardo","userId":"03106774322600334169"}},"outputId":"6b1f3ad0-8d46-4138-de9a-d169a8a095f7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'history = model.fit(train_generator,\\n                     epochs = 60,\\n                     #steps_per_epoch = train_samples,\\n                     shuffle = True,\\n                     workers=8,\\n                     callbacks = Checkpoint,\\n                     validation_data = validation_generator,\\n                     #validation_steps = train_samples\\n                    )\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":56}],"source":["model.load_weights(load_filepath)\n","\n","# history = model.fit(train_generator,\n","#                      epochs = 60,\n","#                      #steps_per_epoch = train_samples,\n","#                      shuffle = True,\n","#                      workers=8,\n","#                      callbacks = Checkpoint,\n","#                      validation_data = validation_generator,\n","#                      #validation_steps = train_samples\n","#                     )\n","\n","#temp = model.fit(train_x,train_y,epochs=24,batch_size=32,validation_data = (test_x,test_y))#,callbacks=[Checkpoint])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCaoKfnNL786","outputId":"33642be9-42ff-4c21-c784-5b68486ba826","executionInfo":{"status":"ok","timestamp":1701866002529,"user_tz":180,"elapsed":3610,"user":{"displayName":"Eduardo","userId":"03106774322600334169"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 - 2s - loss: 6.3322 - accuracy: 0.0000e+00 - 2s/epoch - 140ms/step\n"]}],"source":["#model.load_weights(checkpoint_filepath)\n","#Yuri\n","\n","loss, acc = model.evaluate(test_x,test_y,verbose=2)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"16hbXes0XCF4sv-PM9nuwZ-0esFcv12Ru","timestamp":1701305074058}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}